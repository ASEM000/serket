
<div align="center">
<img width="350px" src="assets/serketLogo.svg"></div>
<h2 align="center">The JAX NN Library.</h2>


![Tests](https://github.com/ASEM000/serket/actions/workflows/tests.yml/badge.svg)
![pyver](https://img.shields.io/badge/python-3.7%203.8%203.9%203.10-red)
![codestyle](https://img.shields.io/badge/codestyle-black-lightgrey)
[![codecov](https://codecov.io/gh/ASEM000/serket/branch/main/graph/badge.svg?token=C6NXOK9EVS)](https://codecov.io/gh/ASEM000/serket)

## ğŸ› ï¸ Installation<a id="Installation"></a>

```python
pip install serket
```


## ğŸ“– Description<a id="Description"></a>
- `serket` aims to be the most intuitive and easy-to-use Neural network library in JAX.
- `serket` is built on top of [`pytreeclass`](https://github.com/ASEM000/pytreeclass)
- `serket` currently implements 
  - `Linear`, `FNN`
  - `Dropout`
  - `Sequential`
  - `Lambda`


## â© Quick Example <a id="QuickExample">

Simple Fully connected neural network.

* model definition
```python

>>> model = Sequential([
    Linear(1,128),
    Lambda(jax.nn.relu),
    Linear(128,128),
    Lambda(jax.nn.relu),
    Linear(128,1),
])

>>> print(model.tree_diagram())
Sequential
    â”œâ”€â”€ Layer_0=Linear
    â”‚   â”œâ”€â”€ weight=f32[1,128]
    â”‚   â”œâ”€â”€ bias=f32[128]
    â”‚   â”œ*â”€ in_features=1
    â”‚   â”œ*â”€ out_features=128
    â”‚   â”œ*â”€ weight_init_func=init(key,shape,dtype)
    â”‚   â””*â”€ bias_init_func=Lambda(key,shape)    
    â”œâ”€â”€ Layer_1=Lambda
    â”‚   â””*â”€ func=relu(*args,**kwargs)   
    â”œâ”€â”€ Layer_2=Linear
    â”‚   â”œâ”€â”€ weight=f32[128,128]
    â”‚   â”œâ”€â”€ bias=f32[128]
    â”‚   â”œ*â”€ in_features=128
    â”‚   â”œ*â”€ out_features=128
    â”‚   â”œ*â”€ weight_init_func=init(key,shape,dtype)
    â”‚   â””*â”€ bias_init_func=Lambda(key,shape)    
    â”œâ”€â”€ Layer_3=Lambda
    â”‚   â””*â”€ func=relu(*args,**kwargs)   
    â””â”€â”€ Layer_4=Linear
        â”œâ”€â”€ weight=f32[128,1]
        â”œâ”€â”€ bias=f32[1]
        â”œ*â”€ in_features=128
        â”œ*â”€ out_features=1
        â”œ*â”€ weight_init_func=init(key,shape,dtype)
        â””*â”€ bias_init_func=Lambda(key,shape)   

>>> print(model.summary())
â”Œâ”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Name   â”‚Type  â”‚Param #â”‚Size    â”‚Config             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Layer_0â”‚Linearâ”‚256    â”‚1.00KB  â”‚weight=f32[1,128]  â”‚
â”‚       â”‚      â”‚(2)    â”‚(56.00B)â”‚bias=f32[128]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Layer_1â”‚Lambdaâ”‚0      â”‚0.00B   â”‚                   â”‚
â”‚       â”‚      â”‚(0)    â”‚(0.00B) â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Layer_2â”‚Linearâ”‚16,512 â”‚64.50KB â”‚weight=f32[128,128]â”‚
â”‚       â”‚      â”‚(2)    â”‚(56.00B)â”‚bias=f32[128]      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Layer_3â”‚Lambdaâ”‚0      â”‚0.00B   â”‚                   â”‚
â”‚       â”‚      â”‚(0)    â”‚(0.00B) â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Layer_4â”‚Linearâ”‚129    â”‚516.00B â”‚weight=f32[128,1]  â”‚
â”‚       â”‚      â”‚(2)    â”‚(56.00B)â”‚bias=f32[1]        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Total # :		16,897(6)
Dynamic #:		16,897(6)
Static/Frozen #:	0(0)
-----------------------------------------------------
Total size :		66.00KB(168.00B)
Dynamic size:		66.00KB(168.00B)
Static/Frozen size:	0.00B(0.00B)
=====================================================

```

* Train
```python
x = jnp.linspace(0,1,100)[:,None]
y = x**3 + jax.random.uniform(jax.random.PRNGKey(0),(100,1))*0.01

@jax.value_and_grad
def loss_func(model,x,y):
    return jnp.mean((model(x)-y)**2)

@jax.jit
def update(model,x,y):
    value,grad = loss_func(model,x,y)
    return value , model - 1e-3*grad

for _ in range(20_000):
    value,model = update(model,x,y)
```